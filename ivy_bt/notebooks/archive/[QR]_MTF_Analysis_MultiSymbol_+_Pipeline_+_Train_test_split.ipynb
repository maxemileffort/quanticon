{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV7cPJRacKqp"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-EnT2J9uAau3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "import pandas_ta as ta\n",
        "\n",
        "from utils import (\n",
        "    get_mtf_data, \n",
        "    apply_hmm_split_logic, \n",
        "    calculate_bot_proxy_returns, \n",
        "    calculate_net_returns\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvigBDa4cNRk"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "di4sNeaFGfH8"
      },
      "outputs": [],
      "source": [
        "def align_mtf_data_with_split(df_fine, df_coarse, symbol, n_regimes=3, train_size=0.6):\n",
        "    \"\"\"\n",
        "    Fits HMM on a training split and predicts on the full set.\n",
        "    \"\"\"\n",
        "    df_fine = df_fine.sort_index()\n",
        "    df_coarse = df_coarse.sort_index()\n",
        "\n",
        "    # 1. Determine Split Point\n",
        "    split_idx = int(len(df_coarse) * train_size)\n",
        "    df_train = df_coarse.iloc[:split_idx]\n",
        "\n",
        "    # 2. Apply HMM Regime Filter (Modified to fit on Train, Predict on All)\n",
        "    # We need to modify apply_hmm_regime_filter slightly or handle it here:\n",
        "    df_coarse_processed, hmm_model = apply_hmm_split_logic(df_coarse, df_train, symbol, n_regimes)\n",
        "\n",
        "    # 3. Perform Merge\n",
        "    aligned_df = pd.merge_asof(\n",
        "        df_fine,\n",
        "        df_coarse_processed.add_suffix('_coarse'),\n",
        "        left_index=True,\n",
        "        right_index=True,\n",
        "        direction='backward'\n",
        "    )\n",
        "\n",
        "    return aligned_df, hmm_model, df_coarse.index[split_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OE7RVmWbSRoa"
      },
      "outputs": [],
      "source": [
        "def calculate_physics_signals(df, symbol, rsi_len=14, sar_start=0.02, sar_inc=0.02, sar_max=0.2):\n",
        "    \"\"\"\n",
        "    Translates the 'Return Stream' Pine Script into Python signals.\n",
        "    Treats price as Position -> Velocity -> Acceleration.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    # 1. Access the correct MultiIndex columns\n",
        "    close = df[('Close', symbol)]\n",
        "    high = df[('High', symbol)]\n",
        "    low = df[('Low', symbol)]\n",
        "\n",
        "    # 2. Basic RSI Calculations\n",
        "    # Note: Pine ta.rsi uses RMA (Running Moving Average)\n",
        "    rsi_close = ta.rsi(close, length=rsi_len).fillna(0.0)\n",
        "    rsi_hi = ta.rsi(high, length=rsi_len).fillna(0.0)\n",
        "    rsi_low = ta.rsi(low, length=rsi_len).fillna(0.0)\n",
        "\n",
        "    # 3. RSI-based Parabolic SAR (Custom Recursive Loop)\n",
        "    # This is the 'pine_sar' logic translated to handle RSI inputs\n",
        "    sar_values = np.zeros(len(rsi_close))\n",
        "    is_below = True # Trend direction\n",
        "    max_min = rsi_hi.iloc[0]\n",
        "    result = rsi_low.iloc[0]\n",
        "    accel = sar_start\n",
        "\n",
        "    # Initializing first values\n",
        "    for i in range(1, len(rsi_close)):\n",
        "        # Recursive SAR calculation\n",
        "        prev_result = result\n",
        "        result = result + accel * (max_min - result)\n",
        "\n",
        "        # Check for Trend Switch\n",
        "        if is_below:\n",
        "            if result > rsi_low.iloc[i]:\n",
        "                is_below = False\n",
        "                result = max(rsi_hi.iloc[i], max_min)\n",
        "                max_min = rsi_low.iloc[i]\n",
        "                accel = sar_start\n",
        "            else:\n",
        "                if rsi_hi.iloc[i] > max_min:\n",
        "                    max_min = rsi_hi.iloc[i]\n",
        "                    accel = min(accel + sar_inc, sar_max)\n",
        "                # SAR Floor logic\n",
        "                result = min(result, rsi_low.iloc[i-1], rsi_low.iloc[i-2] if i>1 else rsi_low.iloc[i-1])\n",
        "        else:\n",
        "            if result < rsi_hi.iloc[i]:\n",
        "                is_below = True\n",
        "                result = min(rsi_low.iloc[i], max_min)\n",
        "                max_min = rsi_hi.iloc[i]\n",
        "                accel = sar_start\n",
        "            else:\n",
        "                if rsi_low.iloc[i] < max_min:\n",
        "                    max_min = rsi_low.iloc[i]\n",
        "                    accel = min(accel + sar_inc, sar_max)\n",
        "                # SAR Ceiling logic\n",
        "                result = max(result, rsi_hi.iloc[i-1], rsi_hi.iloc[i-2] if i>1 else rsi_hi.iloc[i-1])\n",
        "\n",
        "        sar_values[i] = result\n",
        "\n",
        "    # 4. The 'Physics' Engine: Velocity & Acceleration\n",
        "    ret_stream = close.diff() # Velocity (Raw)\n",
        "    velocity_ema = ta.ema(ret_stream, length=5) # Velocity (Smoothed)\n",
        "    acceleration = velocity_ema.diff() # Acceleration (Derivative of Velocity)\n",
        "\n",
        "    # 5. Trend Filter\n",
        "    rsi_ema = ta.ema(rsi_close, length=5)\n",
        "\n",
        "    # 6. Signal Generation\n",
        "    # Long: Positive Velocity AND Positive Acceleration AND Price/RSI Trend is Up\n",
        "    long_cond = (velocity_ema > 0) & (acceleration > 0) & (rsi_ema > sar_values)\n",
        "    short_cond = (velocity_ema < 0) & (acceleration < 0) & (rsi_ema < sar_values)\n",
        "\n",
        "    # Map back to DataFrame\n",
        "    df[('Signal', 'Long')] = long_cond.astype(int).diff().fillna(0) == 1\n",
        "    df[('Signal', 'Short')] = short_cond.astype(int).diff().fillna(0) == 1\n",
        "\n",
        "    # Keep the values for debugging/plotting\n",
        "    df[('Physics', 'Velocity')] = velocity_ema\n",
        "    df[('Physics', 'Acceleration')] = acceleration\n",
        "    df[('Indicator', 'SAR_RSI')] = sar_values\n",
        "    df[('Indicator', 'RSI_EMA')] = rsi_ema\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ZQwhZ8gJFC"
      },
      "source": [
        "## Pick Ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KXEaSrbDjVJc"
      },
      "outputs": [],
      "source": [
        "crypto_crosswalk = pd.DataFrame([\n",
        "    (\"AAVEUSD\", \"AAVE-USD\"),    (\"ADAUSD\", \"ADA-USD\"),\n",
        "    (\"AIXBTUSD\", \"AIXBT-USD\"),  (\"ALGOUSD\", \"ALGO-USD\"),    (\"ARBUSD\", \"ARB-USD\"),\n",
        "    (\"ATOMUSD\", \"ATOM-USD\"),    (\"AVAXUSD\", \"AVAX-USD\"),\n",
        "    (\"BCHUSD\", \"BCH-USD\"),    (\"BNBUSD\", \"BNB-USD\"),    (\"BONKUSD\", \"BONK-USD\"),\n",
        "    (\"BTCUSD\", \"BTC-USD\"),    (\"DOGEUSD\", \"DOGE-USD\"),\n",
        "    (\"DOTUSD\", \"DOT-USD\"),    (\"ETHUSD\", \"ETH-USD\"),\n",
        "    (\"FARTCOINUSD\", \"FARTCOIN-USD\"),    (\"FILUSD\", \"FIL-USD\"),\n",
        "    (\"FLOKIUSD\", \"FLOKI-USD\"),(\"HBARUSD\", \"HBAR-USD\"),\n",
        "    (\"INJUSD\", \"INJ-USD\"),    (\"IPUSD\", \"IP-USD\"),    (\"JTOUSD\", \"JTO-USD\"),\n",
        "    (\"JUPUSD\", \"JUP-USD\"),    (\"KAITOUSD\", \"KAITO-USD\"),    (\"LDOUSD\", \"LDO-USD\"),\n",
        "    (\"LINKUSD\", \"LINK-USD\"),    (\"LTCUSD\", \"LTC-USD\"),\n",
        "    (\"NEARUSD\", \"NEAR-USD\"),    (\"ONDOUSD\", \"ONDO-USD\"),    (\"OPUSD\", \"OP-USD\"),\n",
        "    (\"ORDIUSD\", \"ORDI-USD\"),\n",
        "    (\"PNUTUSD\", \"PNUT-USD\"),  (\"RENDERUSD\", \"RENDER-USD\"),    (\"SUSD\", \"SUSD-USD\"),\n",
        "    (\"SHIBUSD\", \"SHIB-USD\"),    (\"SOLUSD\", \"SOL-USD\"),    (\"TIAUSD\", \"TIA-USD\"),\n",
        "    (\"TONUSD\", \"TON-USD\"),    (\"TRUMPUSD\", \"TRUMP-USD\"),    (\"TRXUSD\", \"TRX-USD\"),\n",
        "    (\"VIRTUALUSD\", \"VIRTUAL-USD\"),    (\"WIFUSD\", \"WIF-USD\"),\n",
        "    (\"WLDUSD\", \"WLD-USD\"),    (\"XPLUSD\", \"XPL-USD\"),    (\"XRPUSD\", \"XRP-USD\"),\n",
        "], columns=[\"breakout_symbol\", \"yfinance_symbol\"])\n",
        "\n",
        "crypto_assets = crypto_crosswalk['yfinance_symbol'].to_list()\n",
        "\n",
        "forex_crosswalk = pd.DataFrame([\n",
        "    # Major pairs\n",
        "    (\"EURUSD\", \"EURUSD=X\"),    (\"GBPUSD\", \"GBPUSD=X\"),    (\"USDJPY\", \"USDJPY=X\"),\n",
        "    (\"USDCHF\", \"USDCHF=X\"),    (\"AUDUSD\", \"AUDUSD=X\"),    (\"USDCAD\", \"USDCAD=X\"),\n",
        "    (\"NZDUSD\", \"NZDUSD=X\"),\n",
        "\n",
        "    # Minor (cross) pairs\n",
        "    (\"EURGBP\", \"EURGBP=X\"),    (\"EURJPY\", \"EURJPY=X\"),    (\"EURCHF\", \"EURCHF=X\"),\n",
        "    (\"EURAUD\", \"EURAUD=X\"),    (\"EURCAD\", \"EURCAD=X\"),    (\"EURNZD\", \"EURNZD=X\"),\n",
        "\n",
        "    (\"GBPJPY\", \"GBPJPY=X\"),    (\"GBPCHF\", \"GBPCHF=X\"),    (\"GBPAUD\", \"GBPAUD=X\"),\n",
        "    (\"GBPCAD\", \"GBPCAD=X\"),    (\"GBPNZD\", \"GBPNZD=X\"),\n",
        "\n",
        "    (\"AUDJPY\", \"AUDJPY=X\"),    (\"AUDCHF\", \"AUDCHF=X\"),    (\"AUDCAD\", \"AUDCAD=X\"),\n",
        "    (\"AUDNZD\", \"AUDNZD=X\"),\n",
        "\n",
        "    (\"CADJPY\", \"CADJPY=X\"),    (\"CADCHF\", \"CADCHF=X\"),\n",
        "\n",
        "    (\"CHFJPY\", \"CHFJPY=X\"),\n",
        "\n",
        "    (\"NZDJPY\", \"NZDJPY=X\"),    (\"NZDCHF\", \"NZDCHF=X\"),    (\"NZDCAD\", \"NZDCAD=X\"),\n",
        "], columns=[\"breakout_symbol\", \"yfinance_symbol\"])\n",
        "\n",
        "forex_assets = forex_crosswalk['yfinance_symbol'].to_list()\n",
        "\n",
        "symbols = [crypto_assets, False]\n",
        "# symbols = [forex_assets, True]\n",
        "\n",
        "\n",
        "IS_FOREX = symbols[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2cMVrS0jZqA"
      },
      "source": [
        "## Regimes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hkfjUGIqff2X"
      },
      "outputs": [],
      "source": [
        "n_regimes = [2]\n",
        "\n",
        "timeframes = ['1h', '1d']\n",
        "\n",
        "start_date = datetime.today() - timedelta(days=730)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BKACQgOPYMxZ",
        "outputId": "f8c7a502-25bf-4273-9d78-41b4d08a758d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 1h for ['AAVE-USD', 'ADA-USD', 'AIXBT-USD', 'ALGO-USD', 'ARB-USD', 'ATOM-USD', 'AVAX-USD', 'BCH-USD', 'BNB-USD', 'BONK-USD', 'BTC-USD', 'DOGE-USD', 'DOT-USD', 'ETH-USD', 'FARTCOIN-USD', 'FIL-USD', 'FLOKI-USD', 'HBAR-USD', 'INJ-USD', 'IP-USD', 'JTO-USD', 'JUP-USD', 'KAITO-USD', 'LDO-USD', 'LINK-USD', 'LTC-USD', 'NEAR-USD', 'ONDO-USD', 'OP-USD', 'ORDI-USD', 'PNUT-USD', 'RENDER-USD', 'SUSD-USD', 'SHIB-USD', 'SOL-USD', 'TIA-USD', 'TON-USD', 'TRUMP-USD', 'TRX-USD', 'VIRTUAL-USD', 'WIF-USD', 'WLD-USD', 'XPL-USD', 'XRP-USD'] starting at 2025-12-03...\n",
            "Fetching 1d for ['AAVE-USD', 'ADA-USD', 'AIXBT-USD', 'ALGO-USD', 'ARB-USD', 'ATOM-USD', 'AVAX-USD', 'BCH-USD', 'BNB-USD', 'BONK-USD', 'BTC-USD', 'DOGE-USD', 'DOT-USD', 'ETH-USD', 'FARTCOIN-USD', 'FIL-USD', 'FLOKI-USD', 'HBAR-USD', 'INJ-USD', 'IP-USD', 'JTO-USD', 'JUP-USD', 'KAITO-USD', 'LDO-USD', 'LINK-USD', 'LTC-USD', 'NEAR-USD', 'ONDO-USD', 'OP-USD', 'ORDI-USD', 'PNUT-USD', 'RENDER-USD', 'SUSD-USD', 'SHIB-USD', 'SOL-USD', 'TIA-USD', 'TON-USD', 'TRUMP-USD', 'TRX-USD', 'VIRTUAL-USD', 'WIF-USD', 'WLD-USD', 'XPL-USD', 'XRP-USD'] starting at 2024-02-02...\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "error_symbols = []\n",
        "\n",
        "raw_data = get_mtf_data(symbols[0], start_date, end_date=None, intervals=timeframes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Se9AbSvIYYZ7",
        "outputId": "a61071f5-1190-4b7c-c3fa-60ef556b93af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Price                           Close                                          \\\n",
              " Ticker                       AAVE-USD   ADA-USD AIXBT-USD  ALGO-USD   ARB-USD   \n",
              " Datetime                                                                        \n",
              " 2025-12-03 15:00:00+00:00  192.944168  0.434333  0.043287  0.140262  0.001175   \n",
              " 2025-12-03 16:00:00+00:00  192.630112  0.437875  0.043234  0.140345  0.001175   \n",
              " 2025-12-03 17:00:00+00:00  194.481491  0.443456  0.043794  0.141508  0.001175   \n",
              " 2025-12-03 18:00:00+00:00  193.707062  0.441559  0.043506  0.141764  0.001175   \n",
              " 2025-12-03 19:00:00+00:00  195.333023  0.444978  0.043631  0.142351  0.001175   \n",
              " \n",
              " Price                                                                   \\\n",
              " Ticker                     ATOM-USD   AVAX-USD     BCH-USD     BNB-USD   \n",
              " Datetime                                                                 \n",
              " 2025-12-03 15:00:00+00:00  2.338500  14.167774  588.704651  897.089783   \n",
              " 2025-12-03 16:00:00+00:00  2.339396  14.304674  599.413269  900.378723   \n",
              " 2025-12-03 17:00:00+00:00  2.367050  14.385775  596.158264  907.448059   \n",
              " 2025-12-03 18:00:00+00:00  2.357128  14.420603  598.532166  902.031006   \n",
              " 2025-12-03 19:00:00+00:00  2.368733  14.481797  598.117310  906.873596   \n",
              " \n",
              " Price                               ...   Volume                            \\\n",
              " Ticker                    BONK-USD  ... SUSD-USD TIA-USD TON-USD TRUMP-USD   \n",
              " Datetime                            ...                                      \n",
              " 2025-12-03 15:00:00+00:00  0.00001  ...        0       0       0         0   \n",
              " 2025-12-03 16:00:00+00:00  0.00001  ...        0       0       0         0   \n",
              " 2025-12-03 17:00:00+00:00  0.00001  ...    40119       0     651         0   \n",
              " 2025-12-03 18:00:00+00:00  0.00001  ...        0       0       0         0   \n",
              " 2025-12-03 19:00:00+00:00  0.00001  ...        0  627224     755         0   \n",
              " \n",
              " Price                                                                          \n",
              " Ticker                    TRX-USD VIRTUAL-USD WIF-USD WLD-USD XPL-USD XRP-USD  \n",
              " Datetime                                                                       \n",
              " 2025-12-03 15:00:00+00:00       0           0       0       0       0       0  \n",
              " 2025-12-03 16:00:00+00:00       0           0       0       0       0       0  \n",
              " 2025-12-03 17:00:00+00:00       0      781680       0       0       0       0  \n",
              " 2025-12-03 18:00:00+00:00       0     4167392       0       0  622784       0  \n",
              " 2025-12-03 19:00:00+00:00       0      859904       0       0       0       0  \n",
              " \n",
              " [5 rows x 220 columns],\n",
              " Price                           Close                                          \\\n",
              " Ticker                       AAVE-USD   ADA-USD AIXBT-USD  ALGO-USD   ARB-USD   \n",
              " Datetime                                                                        \n",
              " 2026-02-01 11:00:00+00:00  126.997559  0.295094  0.025042  0.103677  0.000899   \n",
              " 2026-02-01 12:00:00+00:00  126.264656  0.293326  0.025029  0.103254  0.000899   \n",
              " 2026-02-01 13:00:00+00:00  125.508461  0.293256  0.025111  0.103141  0.000899   \n",
              " 2026-02-01 14:00:00+00:00  125.979759  0.293237  0.025034  0.103025  0.000899   \n",
              " 2026-02-01 15:00:00+00:00  125.779869  0.292699  0.024983  0.102827  0.000899   \n",
              " \n",
              " Price                                                                   \\\n",
              " Ticker                     ATOM-USD   AVAX-USD     BCH-USD     BNB-USD   \n",
              " Datetime                                                                 \n",
              " 2026-02-01 11:00:00+00:00  1.967257  10.121046  534.589844  773.220642   \n",
              " 2026-02-01 12:00:00+00:00  1.960688  10.065272  533.342957  769.066101   \n",
              " 2026-02-01 13:00:00+00:00  1.963733  10.056303  530.305908  764.986633   \n",
              " 2026-02-01 14:00:00+00:00  1.957378  10.046324  531.235779  763.239258   \n",
              " 2026-02-01 15:00:00+00:00  1.953640  10.026253  530.629272  762.264038   \n",
              " \n",
              " Price                                ...   Volume                            \\\n",
              " Ticker                     BONK-USD  ... SUSD-USD TIA-USD TON-USD TRUMP-USD   \n",
              " Datetime                             ...                                      \n",
              " 2026-02-01 11:00:00+00:00  0.000007  ...    28656     616     135         0   \n",
              " 2026-02-01 12:00:00+00:00  0.000007  ...    26299       0       0         0   \n",
              " 2026-02-01 13:00:00+00:00  0.000007  ...        0       0       0         0   \n",
              " 2026-02-01 14:00:00+00:00  0.000007  ...     6980       0       0         0   \n",
              " 2026-02-01 15:00:00+00:00  0.000007  ...        1       0       0         0   \n",
              " \n",
              " Price                                                                   \\\n",
              " Ticker                    TRX-USD VIRTUAL-USD  WIF-USD WLD-USD XPL-USD   \n",
              " Datetime                                                                 \n",
              " 2026-02-01 11:00:00+00:00       0     1406816   594480       0  469032   \n",
              " 2026-02-01 12:00:00+00:00       0           0  4686368       0       0   \n",
              " 2026-02-01 13:00:00+00:00       0           0  2501824  754752       0   \n",
              " 2026-02-01 14:00:00+00:00       0           0        0       0       0   \n",
              " 2026-02-01 15:00:00+00:00       0           0        0       0   11856   \n",
              " \n",
              " Price                                \n",
              " Ticker                      XRP-USD  \n",
              " Datetime                             \n",
              " 2026-02-01 11:00:00+00:00  53287936  \n",
              " 2026-02-01 12:00:00+00:00         0  \n",
              " 2026-02-01 13:00:00+00:00         0  \n",
              " 2026-02-01 14:00:00+00:00         0  \n",
              " 2026-02-01 15:00:00+00:00         0  \n",
              " \n",
              " [5 rows x 220 columns])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data[0].head(), raw_data[0].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3WhrvjSnbZWe"
      },
      "outputs": [],
      "source": [
        "data = dict.fromkeys(symbols[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v3JbHVrnAeYs"
      },
      "outputs": [],
      "source": [
        "for s in symbols[0]:\n",
        "  try:\n",
        "    # Extract data for the current symbol 's' from the multi-symbol raw_data\n",
        "    # raw_data[0] is the fine-grained data (e.g., 1h), raw_data[1] is the coarse-grained data (e.g., 1d)\n",
        "    df_fine_for_symbol = raw_data[0].loc[:, (slice(None), s)].copy()\n",
        "    df_coarse_for_symbol = raw_data[1].loc[:, (slice(None), s)].copy()\n",
        "\n",
        "    # Ensure indices are uniformly of type datetime64[ns, UTC] for merging consistency\n",
        "    df_fine_for_symbol.index = pd.to_datetime(df_fine_for_symbol.index, utc=True).astype('datetime64[ns, UTC]')\n",
        "    df_coarse_for_symbol.index = pd.to_datetime(df_coarse_for_symbol.index, utc=True).astype('datetime64[ns, UTC]')\n",
        "\n",
        "    # The align_mtf_data_with_split function returns aligned_df, hmm_model, split_date.\n",
        "    # However, the subsequent cell `xizpvnGxuS98` expects `data[s]` to be a tuple `(df_fine, df_coarse)`.\n",
        "    # So, we store the symbol-specific, standardized fine and coarse dataframes here.\n",
        "    data[s] = (df_fine_for_symbol, df_coarse_for_symbol)\n",
        "\n",
        "  except IndexError as e:\n",
        "    print(f\"Error extracting data for {s} from raw_data: {e}\")\n",
        "    error_symbols.append([s,e])\n",
        "  except Exception as e: # Catch other potential errors too, like MergeError\n",
        "    print(f\"An error occurred for {s}: {e}\")\n",
        "    error_symbols.append([s,e])\n",
        "  time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xizpvnGxuS98",
        "outputId": "d9ad1237-a7d9-4cd0-c7b4-8b101544328a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Max\\Desktop\\projects\\quanticon\\ivy_bt\\notebooks\\utils.py:25: FutureWarning: Hour.delta is deprecated and will be removed in a future version. Use pd.Timedelta(obj) instead\n",
            "  delta = pd.tseries.frequencies.to_offset(inferred).delta\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Must have equal len keys and value when setting with an ndarray",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Split Performance\u001b[39;00m\n\u001b[32m     84\u001b[39m final_df[\u001b[33m'\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m'\u001b[39m] = np.where(final_df.index < split_date, \u001b[33m'\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTest\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m stats_df, risk_stats = \u001b[43mcalculate_net_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIS_FOREX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m proxy_df = calculate_bot_proxy_returns(final_df, s)\n\u001b[32m     88\u001b[39m proxy_dfs.append(proxy_df)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Max\\Desktop\\projects\\quanticon\\ivy_bt\\notebooks\\utils.py:199\u001b[39m, in \u001b[36mcalculate_net_returns\u001b[39m\u001b[34m(df, is_forex)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# 2. Strategy Returns (Flipped for Shorts)\u001b[39;00m\n\u001b[32m    198\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mStrategy_Ret\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEntry\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLong\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStrategy_Ret\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = df[\u001b[33m'\u001b[39m\u001b[33mReturns\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    200\u001b[39m df.loc[df[\u001b[33m'\u001b[39m\u001b[33mEntry\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mShort\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStrategy_Ret\u001b[39m\u001b[33m'\u001b[39m] = -df[\u001b[33m'\u001b[39m\u001b[33mReturns\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# 3. Apply Costs\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Max\\Desktop\\projects\\quanticon\\pyquant\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:912\u001b[39m, in \u001b[36m_LocationIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    909\u001b[39m \u001b[38;5;28mself\u001b[39m._has_valid_setitem_indexer(key)\n\u001b[32m    911\u001b[39m iloc = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33miloc\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj.iloc\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[43miloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Max\\Desktop\\projects\\quanticon\\pyquant\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1943\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1940\u001b[39m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1943\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_single_block(indexer, value, name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Max\\Desktop\\projects\\quanticon\\pyquant\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1983\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer_split_path\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1978\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[32m   1980\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.ndim(value) == \u001b[32m2\u001b[39m:\n\u001b[32m   1981\u001b[39m     \u001b[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[32m   1982\u001b[39m     \u001b[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer_2d_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer == \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[32m   1986\u001b[39m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_single_column(ilocs[\u001b[32m0\u001b[39m], value, pi)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Max\\Desktop\\projects\\quanticon\\pyquant\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2049\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[39m\u001b[34m(self, indexer, value)\u001b[39m\n\u001b[32m   2047\u001b[39m     value = np.array(value, dtype=\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m   2048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) != value.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2049\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2050\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2051\u001b[39m     )\n\u001b[32m   2053\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[32m   2054\u001b[39m     value_col = value[:, i]\n",
            "\u001b[31mValueError\u001b[39m: Must have equal len keys and value when setting with an ndarray"
          ]
        }
      ],
      "source": [
        "results_split = []\n",
        "\n",
        "risk_stat_lst = []\n",
        "\n",
        "proxy_dfs = []\n",
        "\n",
        "for s in [s for s in symbols[0]]:\n",
        "    for n_r in n_regimes:\n",
        "        # Align data and get the split date\n",
        "        # (Modified align_mtf_data to use apply_hmm_split_logic)\n",
        "        try:\n",
        "          df_fine, df_coarse = data[s][0], data[s][1]\n",
        "          df_coarse_split, hmm_model, split_date = apply_hmm_split_logic(df_coarse, s, n_r)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          continue\n",
        "\n",
        "\n",
        "        # Ensure indices are timezone-aware and in the same timezone (UTC) for consistent merging\n",
        "        df_fine.index = pd.to_datetime(df_fine.index)\n",
        "        if df_fine.index.tz is None:\n",
        "            df_fine.index = df_fine.index.tz_localize('UTC')\n",
        "        else:\n",
        "            df_fine.index = df_fine.index.tz_convert('UTC')\n",
        "\n",
        "        df_coarse_split.index = pd.to_datetime(df_coarse_split.index)\n",
        "        if df_coarse_split.index.tz is None:\n",
        "            df_coarse_split.index = df_coarse_split.index.tz_localize('UTC')\n",
        "        else:\n",
        "            df_coarse_split.index = df_coarse_split.index.tz_convert('UTC')\n",
        "\n",
        "        # Localize split_date to UTC to match final_df.index before comparison\n",
        "        split_date_obj = pd.to_datetime(split_date)\n",
        "        if split_date_obj.tz is None:\n",
        "            split_date = split_date_obj.tz_localize('UTC')\n",
        "        else:\n",
        "            split_date = split_date_obj.tz_convert('UTC')\n",
        "\n",
        "        # Align\n",
        "        final_df = pd.merge_asof(\n",
        "            df_fine.sort_index(),\n",
        "            df_coarse_split.add_suffix('_coarse').sort_index(),\n",
        "            left_index=True, right_index=True, direction='backward'\n",
        "        )\n",
        "\n",
        "        # Physics Signals\n",
        "        final_df = calculate_physics_signals(final_df, s)\n",
        "\n",
        "        bull_regime = max(final_df[('Regime_coarse', 'HMM_coarse')])\n",
        "        bear_regime = min(final_df[('Regime_coarse', 'HMM_coarse')])\n",
        "        trends = [bear_regime, bull_regime]\n",
        "        flat_regime = [n for n in final_df[('Regime_coarse', 'HMM_coarse')].unique() if n not in trends ]\n",
        "\n",
        "        # Filter for \"HMM Bullish\" + \"Physics Long\"\n",
        "        long_f1 = final_df[('Regime_coarse', 'HMM_coarse')] == bull_regime\n",
        "        long_f2 = final_df[('Signal', 'Long')] == True\n",
        "\n",
        "        short_f1 = final_df[('Regime_coarse', 'HMM_coarse')] == bear_regime\n",
        "        short_f2 = final_df[('Signal', 'Short')] == True\n",
        "\n",
        "        flat_f1 = final_df[('Regime_coarse', 'HMM_coarse')].isin(flat_regime)\n",
        "\n",
        "        final_df['Entry'] = None\n",
        "\n",
        "        final_df['Entry'] = final_df['Entry'].mask((long_f1) & (long_f2), 'Long')\n",
        "        final_df['Entry'] = final_df['Entry'].mask((short_f1) & (short_f2), 'Short')\n",
        "        final_df['Entry'] = final_df['Entry'].mask((flat_f1), 'Flat')\n",
        "        final_df['Entry'] = final_df['Entry'].ffill()\n",
        "        # Enter on the next bar to offset lookahead bias\n",
        "        # final_df['Entry'] = final_df['Entry'].shift(1)\n",
        "        final_df['Hold'] = 'Hold'\n",
        "\n",
        "        # # Entry Logic\n",
        "        # final_df['Entry'] = 'Flat'\n",
        "        # final_df.loc[(final_df[('Regime_coarse', 'HMM_coarse')] == bull_regime) &\n",
        "        #              (final_df[('Signal', 'Long')]), 'Entry'] = 'Long'\n",
        "        # final_df.loc[(final_df[('Regime_coarse', 'HMM_coarse')] == bear_regime) &\n",
        "        #              (final_df[('Signal', 'Short')]), 'Entry'] = 'Short'\n",
        "\n",
        "        # Returns\n",
        "        final_df['Returns'] = final_df[('Close', s)].pct_change()\n",
        "\n",
        "        # Split Performance\n",
        "        final_df['Dataset'] = np.where(final_df.index < split_date, 'Train', 'Test')\n",
        "\n",
        "        stats_df, risk_stats = calculate_net_returns(final_df, is_forex=IS_FOREX)\n",
        "        proxy_df = calculate_bot_proxy_returns(final_df, s)\n",
        "        proxy_dfs.append(proxy_df)\n",
        "        # print(stats_df)\n",
        "        print(risk_stats)\n",
        "        print('=' * 100)\n",
        "        risk_stat_lst.append([s, risk_stats])\n",
        "\n",
        "        stats = final_df.groupby(['Dataset', 'Entry'])['Returns'].sum().reset_index()\n",
        "        stats['Ticker'] = s\n",
        "        stats['N_Regimes'] = n_r\n",
        "        results_split.append(stats)\n",
        "\n",
        "# Combine into a master DataFrame\n",
        "full_results_df = pd.concat(results_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR4bWFoCcOhh"
      },
      "outputs": [],
      "source": [
        "proxy_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99RvyI-E4w0c"
      },
      "outputs": [],
      "source": [
        "for r in risk_stat_lst:\n",
        "  print(r[0])\n",
        "  print(r[1])\n",
        "  print('='*20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DO06AgM1ebU"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter for Long signals to check consistency\n",
        "long_comparison = full_results_df[full_results_df['Entry'] == 'Long']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=long_comparison, x='Ticker', y='Returns', hue='Dataset')\n",
        "plt.title(\"Consistency Check: Long Strategy Returns (Train vs Test)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTgQFC__jv1n"
      },
      "outputs": [],
      "source": [
        "# Filter for Long signals to check consistency\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=full_results_df, x='Entry', y='Returns', hue='Dataset')\n",
        "plt.title(\"Consistency Check: Long Strategy Returns (Train vs Test)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oih_l7KLMFp"
      },
      "outputs": [],
      "source": [
        "# Filter for Long signals to check consistency\n",
        "non_flats = full_results_df[full_results_df['Entry'] != 'Flat']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=non_flats, x='Entry', y='Returns', hue='Dataset')\n",
        "plt.title(\"Consistency Check: Long Strategy Returns (Train vs Test)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRtmTyXR30Va"
      },
      "outputs": [],
      "source": [
        "full_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d_sY2XOQe6d"
      },
      "outputs": [],
      "source": [
        "proxy_dfs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQHXMVlztK2-"
      },
      "outputs": [],
      "source": [
        "for df in proxy_dfs:\n",
        "    ticker = df.columns[0][1]\n",
        "    ret_cols = ['Entry', 'Returns', 'Dataset',\n",
        "                'Position_Change', 'Strategy_Ret',\n",
        "                'Net_Ret', 'Pos', 'Active_Pos',\n",
        "                'Is_Entry', 'Is_Exit',\n",
        "                'Raw_Asset_Ret', 'Bot_Net_Ret'\n",
        "               ]\n",
        "    ret_df = df[ret_cols].copy()\n",
        "\n",
        "    # FIX: Flatten the MultiIndex columns to just the metric names\n",
        "    # This turns ('AAPL', 'Returns') into just 'Returns'\n",
        "    ret_df.columns = [col[0] if isinstance(col, tuple) else col for col in ret_df.columns]\n",
        "\n",
        "\n",
        "    # Define the return columns you want to aggregate\n",
        "    return_metrics = ['Returns', 'Strategy_Ret', 'Net_Ret', 'Raw_Asset_Ret', 'Bot_Net_Ret']\n",
        "\n",
        "    # 1. Aggregate the returns (Sum) grouped by 'Dataset'\n",
        "    # 2. Plot as a clustered bar chart\n",
        "    ax = ret_df.groupby(['Entry', 'Dataset'])[return_metrics].sum().plot(\n",
        "        kind='bar',\n",
        "        figsize=(6, 3),\n",
        "        width=0.8\n",
        "    )\n",
        "\n",
        "    # Formatting the plot\n",
        "    plt.title(f'Aggregate Returns Comparison - {ticker}', fontsize=14)\n",
        "    plt.ylabel('Total Return', fontsize=12)\n",
        "    plt.xlabel('Dataset', fontsize=12)\n",
        "    plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
